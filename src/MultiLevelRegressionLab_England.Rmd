---
title: "ESS 575: Multi-Level Regression Lab"
author: "Team England" 
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
linkcolor: blue
header-includes:
  - \usepackage{caption}
  - \captionsetup[figure]{labelformat=empty}
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding){ 
    out_dir <- '../';
    rmarkdown::render(inputFile, encoding = encoding, output_file=file.path(dirname(inputFile), out_dir, 'MultiLevelRegressionLab_England.pdf')) 
  })
---

Team England:

  - Caroline Blommel
  - Carolyn Coyle
  - Bryn Crosby
  - George Woolsey
  
cblommel@mail.colostate.edu, carolynm@mail.colostate.edu, brcrosby@rams.colostate.edu, george.woolsey@colostate.edu

```{r setup, include=F}
# knit options
knitr::opts_chunk$set(
  echo = TRUE
  , warning = FALSE
  , message = FALSE
  , fig.height = 5
  , fig.width = 7
  , eval = TRUE
)
```

# Preliminaries

## Motivation

Each section of this lab has two parts -- a model *building* exercise and a model *coding* exercise. The material covered here is important and broadly useful -- building multi-levels models is a true workhorse for understanding ecological processes because so many problems contain information at nested spatial scales, levels of organization, or categories. It will be worthwhile to dig in deeply to understand it. The big picture is to demonstrate the flexibility that you gain as a modeler by understanding basic principles of Bayesian analysis. To accomplish that, these exercises will reinforce the following:

1. Diagramming and writing hierarchical models
2. Using data to model parameters
3. JAGS coding
4. Creating index variables, a critically important and useful skill
5. Posterior predictive checks

## Introduction

Ecological data are often collected at multiple scales or levels of organization in nested designs. Group is a catchall term for the upper level in many different types of nested hierarchies. Groups could logically be composed of populations, locations, species, treatments, life stages, and individual studies, or really, any sensible category. We have measurements within groups on individual organisms, plots, species, time periods, and so on. We may also have measurements on the groups themselves, that is, covariates that apply at the upper level of organization or spatial scale or the category that contains the measurements. Multilevel models represent the way that a quantity of interest responds to the combined influence of observations taken at the group level and within the group. 

Nitrous oxide $\textrm{N} _2 \textrm{O}$, a greenhouse gas roughly 300 times more potent than carbon dioxide in forcing atmospheric warming, is emitted when synthetic nitrogenous fertilizers are added to soils. Qian and colleagues (2010) conducted a Bayesian meta-analysis of $\textrm{N} _2 \textrm{O}$ emissions (g N $\cdot$ ha^-1^ $\cdot$ d^-1^)  from agricultural soils using data from a study conducted by Carey (2007), who reviewed 164 relevant studies. Studies occurred at different locations, forming a group-level hierarchy (we will use only sites that have both nitrogen and carbon data, which reduces the number of sites to 107 in the analysis here). Soil carbon content (g $\cdot$ organic C $\cdot$ g^-1^ soil dry matter) was measured as a group-level covariate and is assumed to be measured without error. Observations of $\textrm{N} _2 \textrm{O}$ emission are also assumed to be measured without error and were paired with measurements of fertilizer addition (kg N$\cdot$ ha^-1^ $\cdot$ year^-1^). The effect of different types of fertilizer was also studied. 

You are going to use these data to build increasingly complex models of $\textrm{N} _2 \textrm{O}$ emission. The initial models will ignore some important covariates as well as how the data are structured hierarchically into sites. This is ok! When writing for a multi-level model like this one, do it incrementally, starting with a separate model for each site (the no-pool model) or a model that ignores sites entirely (the pooled model). After getting these models to work you can add complexity by drawing the intercept for each model from a distribution, before pursuing further refinements.  We **strongly sugggest** this approach because it is always best to do the simple thing first: there is less to go wrong. Also, when things do go wrong it will be clearer as to what is causing the problem.

## R libraries needed for this lab

You need to load the following libraries. Set the seed to 10 to compare your answers to ours.
 
```{r, eval=T}
# bread-and-butter
library(tidyverse)
library(lubridate)
library(viridis)
library(scales)
library(latex2exp)
# visualization
library(cowplot)
library(kableExtra)
# jags and bayesian
library(actuar)
library(rjags)
library(ggthemes)
library(gridExtra)
library(MCMCvis)
library(HDInterval)
library(BayesNSF)
library(reshape2)
#set seed
set.seed(10)
```
 
# Pooled

## Diagramming and writing the pooled model

Let’s begin by ignoring the data on soil carbon and fertilizer type. In addition, we will ignore site, such that all observations are treated as independent from one another. This is what’s known as complete pooling - see Gelman and Hill, (2007), or just a pooled model. You will use a linearized power function for your deterministic model of emissions as a function of nitrogen input:

$$
\begin{aligned}
\mu_{i} = \gamma x_{i}^{\beta}\\
\alpha = \log \bigl(\gamma \bigr)\\
\log \bigl(\mu_{i} \bigr)  = \alpha+\beta \bigl(\log(x_i) \bigr)\\
g \bigl(\alpha,\beta,\log(x_i) \bigr)  = \alpha + \beta \bigl(\log(x_i) \bigr) \\
\end{aligned}
$$

### Question 1 

Interpret the coefficients $\alpha$, $\beta$, and $\gamma$ in this model.

\textcolor{violet}{We are interested in modelling $\textrm{N} _2 \textrm{O}$ emission as a function of soil carbon content, fertilizer addition, and fertilizer type. We begin by ignoring the data on soil carbon and fertilizer type. In addition, we initially ignore site-level variations by pooling the data from different sites (i.e. a pooled model). In the model $\mu_{i} = \gamma x_{i}^{\beta}$, $\gamma$ is the baseline scale factor for the fertilizer addition rate ($x_{i}$) impact to $\textrm{N} _2 \textrm{O}$ emission. The exponent $\beta$ allows for the influence of fertilizer input on $\textrm{N} _2 \textrm{O}$ emission to vary with the rate of fertilizer input. Exponential regression models are used to model situations in which growth/change begins slowly and then accelerates rapidly without bound, or where decay begins rapidly and then slows down to get closer and closer to zero. The transformation $\alpha = \log(\gamma)$ allows for linear representation of the deterministic model.}

### Question 2

Draw a Bayesian network for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{i}$) on fertilizer addition ($x_{i}$).

```{r, echo=FALSE, out.width="50%", out.height="50%", fig.cap="DAG", fig.align='center'}
knitr::include_graphics("../data/DAG1.jpg")
```

### Question 3

Write out the joint distribution for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{i}$) on fertilizer addition ($x_{i}$). Start by using generic `[ ]`. Use $\sigma^{2}$ to represent the uncertainty in your model realizing that you might need moment matching when you choose a specific distribution. 

$$
\bigl[ \alpha,\beta,\sigma^2 \mid y_i\bigr] \propto \prod_{i=1}^{n} \bigl[ \log(y_{i}) \mid g \bigl( \alpha, \beta, \log(x_i)  \bigr), \sigma^{2}\bigr][\alpha]\bigl[ \beta\bigr]\bigl[ \sigma \bigr]
$$

### Question 4

Finish by choosing specific distributions for likelihoods and priors. You will use the math in the answer as a template to code your model in the subsequent exercises. What are assuming about the distribution of the untransformed $\mu_i$? 


$$
\bigl[ \alpha,\beta,\sigma^2 \mid y_i\bigr] \propto \prod_{i=1}^{n} {\sf normal} \bigr( \log(y_{i}) \mid g \bigl( \alpha, \beta, \log(x_i)  \bigr), \sigma^{2}\bigr) \times {\sf normal} \bigr(\alpha \mid 0,10000\bigr)  \times {\sf normal} \bigr(\beta \mid 0,10000\bigr) \times {\sf uniform}\bigr(\sigma \mid 0, 100 \bigl)
$$

### Question 5

What is the hypothesis represented by this model?

\textcolor{violet}{We are ignoring site-level variations by pooling the data from different sites (i.e. a pooled model). This means that we are assuming that the emissions response to nitrogen addition does not vary across sites. In this pooled model, we are allowing $\textrm{N} _2 \textrm{O}$ emission to increase exponentially with fertilizer application rate.}

## Visualizing the pooled data

It is always a good idea to look at the data. Examine the head of the data frame for emissions. Note that the columns `group.index` and `fert.index` contain indices for sites and fertilizer types. We are going to ignore these for now since the pooled model does not take these into account. Use the code below to plot $\textrm{N} _2 \textrm{O}$ emissions as a function of fertilizer input for both the logged and unlogged data. 

```{r}
# view the first few rows of data
BayesNSF::N2OEmission %>% 
  head()
# data structure
BayesNSF::N2OEmission %>% 
  dplyr::glimpse()
```

We are going to use `ggplot` to visualize the data in this lab. If you are unfamiliar with this package, don't worry. We will provide you will all the codes you need and help your get oriented. We think you will find the plotting functions in `ggplot` very powerful and intuitive. We start by using `ggplot` to load the data frame we will plot data from. Then we add `geom_point` and use the `aes` argument (the aesthetic mappings) to define the x and y values for the points. All `ggplot` functions require you to define the aesthetic mappings as needed. Here, they are the same as setting x and y in the normal plot functions. The other big difference is that `ggplot` allows you to add successive layers to the plot using the `+` operator. You will see later on that this offers a lot of flexibility. We add the `geom_line` feature and then set the theme to `minimal`. Lastly, we use the `grid.arrange` function to position multiple plots at once. This is similar to using `mfrow` with `par`.

```{r}
# untransformed
g1 <- ggplot(data = BayesNSF::N2OEmission) +
  geom_point(
    mapping = aes(y = emission, x = n.input)
    , alpha = 3/10
    , shape = 21
    , colour = "black"
    , fill = "brown"
    , size = 3
  ) +
  theme_minimal()
# log transformed
g2 <- ggplot(data = BayesNSF::N2OEmission) +
  geom_point(
    mapping = aes(y = log(emission), x = log(n.input))
    , alpha = 3/10
    , shape = 21
    , colour = "black"
    , fill = "brown"
    , size = 3
  ) +
  theme_minimal() 
# plot side by side
gridExtra::grid.arrange(g1, g2, nrow = 1)
```

### Fitting the pooled model with JAGS

You will now write a simple, pooled model where you gloss over differences in sites and fertilizer types and lump everything into a set of $x$ and $y$ pairs using the R template provided below. It is imperative that you study the data statement and match the variable names in your JAGS code to the left hand side of the = in the data list. Call the intercept `alpha`, the slope `beta` and use `sigma` to name the standard deviation in the likelihood. Also notice, that we center the nitrogen input covariate to speed convergence. You could also standardize this as well.

In addition to fitting this model, we would like you to have JAGS predict the mean logged $\textrm{N} _2 \textrm{O}$ emissions and the median unlogged $\textrm{N} _2 \textrm{O}$ emissions as a function of soil fertilizer input. (Why median? Hint: think back to the distribution of the untransformed data above in question 3 above). To help you out we have provided the range of $\textrm{N} _2 \textrm{O}$ values to predict over as the third element in the `data` list. Make sure you understand how we chose these values.

Note that in this problem and the ones that follow we have set up the data and the initial conditions for you. This will save time and frustration, allowing you to concentrate on writing code for the model but you must pay attention to the names we give in the `data` and `inits` lists.  These must agree with the variable names in your model. Please see any of the course instructors if there is anything that you don't understand about these lists.

```{r}
n.input.pred <- seq(min(BayesNSF::N2OEmission$n.input), max(BayesNSF::N2OEmission$n.input), 10)

data = list(
  log.emission = log(BayesNSF::N2OEmission$emission) %>% 
      as.double()
  , log.n.input.centered = log(BayesNSF::N2OEmission$n.input) - 
      mean(log(BayesNSF::N2OEmission$n.input)) %>% 
        as.double()
  , log.n.input.centered.pred = log(n.input.pred) - 
      mean(log(BayesNSF::N2OEmission$n.input)) %>% 
        as.double()
)

inits = list(
  list(alpha = 0, beta = .5, sigma = 50)
  , list(alpha = 1, beta = 1.5, sigma = 10)
  , list(alpha = 2, beta = .75, sigma = 20)
)
```

### Question 6

Write the code for the model. Compile the model and execute the MCMC to produce a coda object. Produce trace plots of the chains for model parameters. Produce a summary table and caterpillar plot for the parameters and tests for convergence including the effective sample size.

#### JAGS Model

```{r, eval=FALSE}
## JAGS Model
model{
  
  # priors
  alpha ~ dnorm(0,1E-6)
  beta ~ dnorm(0,1E-6)
  sigma ~ dunif(0,100)
  tau <- 1/sigma^2

  # likelihood
  for (i in 1:length(log.emission)) {
    log_mu[i] <- alpha + beta * log.n.input.centered[i]
    log.emission[i] ~ dnorm(log_mu[i], tau)
  }

  ## quantities of interest
    # predicted emissions
    for (j in 1:length(log.n.input.centered.pred)) {
      log_mu_pred[j] <- alpha + beta * log.n.input.centered.pred[j]
      mu_pred[j] <- exp(log_mu_pred[j])
    }
}
```

#### Implement JAGS Model

```{r}
##################################################################
# insert JAGS model code into an R script
##################################################################
{ # Extra bracket needed only for R markdown files - see answers
  sink("NO2JAGS_pooled.R") # This is the file name for the jags code
  cat("
  model{
      # priors
      alpha ~ dnorm(0,1E-6)
      beta ~ dnorm(0,1E-6)
      sigma ~ dunif(0,100)
      tau <- 1/sigma^2
    
      # likelihood
      for (i in 1:length(log.emission)) {
        log_mu[i] <- alpha + beta * log.n.input.centered[i]
        log.emission[i] ~ dnorm(log_mu[i], tau)
      }
    
      ## quantities of interest
        # predicted emissions
        for (j in 1:length(log.n.input.centered.pred)) {
          log_mu_pred[j] <- alpha + beta * log.n.input.centered.pred[j]
          mu_pred[j] <- exp(log_mu_pred[j])
        }
  }
  ", fill = TRUE)
  sink()
}
################################################################
# implement model
##################################################################
# specify 3 scalars, n.adapt, n.update, and n.iter
# n.adapt = number of iterations that JAGS will use to choose the sampler 
  # and to assure optimum mixing of the MCMC chain
n.adapt = 2000
# n.update = number of iterations that will be discarded to allow the chain to 
#   converge before iterations are stored (aka, burn-in)
n.update = 10000
# n.iter = number of iterations that will be stored in the 
  # final chain as samples from the posterior distribution
n.iter = 10000
######################
# Call to JAGS
######################
jm = rjags::jags.model(
  file = "NO2JAGS_pooled.R"
  , data = data
  , inits = inits
  , n.chains = length(inits)
  , n.adapt = n.adapt
)
stats::update(jm, n.iter = n.update)
# save the coda object (more precisely, an mcmc.list object) to R as "zc"
zc_pooled = rjags::coda.samples(
  model = jm
  , variable.names = c("alpha", "beta", "sigma", "tau", "log_mu_pred", "mu_pred")
  # , variable.names = c("a", "b", "p")
  , n.iter = n.iter
  , n.thin = 1
)
```

#### Model Output

Produce trace plots of the chains for model parameters. Produce a summary table and caterpillar plot for the parameters and tests for convergence including the effective sample size.

```{r}
#####################
# check output
#####################
# trace plot
MCMCvis::MCMCtrace(zc_pooled, params = c("alpha", "beta", "sigma"), pdf = FALSE)
# summary
MCMCvis::MCMCsummary(zc_pooled, params = c("alpha", "beta", "sigma"))
# Caterpillar plots
MCMCvis::MCMCplot(zc_pooled, params = c("alpha", "beta", "sigma"))
```

```{r, echo=FALSE, eval=FALSE}
# Heidelberger and Welch diagnostic
coda::heidel.diag(zc_pooled)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_pth",ls())])
gc()
```

## Visualizing the pooled model predictions

Let's overlay the predicted mean logged $\textrm{N} _2 \textrm{O}$ emissions and median unlogged $\textrm{N} _2 \textrm{O}$ emissions as a function of soil fertilizer input from the pooled model on top of the raw data. We summarize the predictions using `MCMCpstr()` twice - once to get the 95% HDPI intervals and a second time to get the posterior median for each fertilizer input value. We combine these predictions into two data frames, one for the logged $\textrm{N} _2 \textrm{O}$ emissions and one for untransformed $\textrm{N} _2 \textrm{O}$ emissions. We append our new graphical elements onto our old plots with the `+` operator. We plot the median of the posterior distribution as a black line with `geom_line()` and the 95% credible intervals as a yellow shaded region using the `geom_ribbon()` function. These data come from a different data frame than the one we used to plot the raw data so we need to add the `data` argument in the new `geom_line` and `geom_ribbon`. Again, we provide you with the code to do this to save time. You will need to modify this code to make similar plots for models you fit in later exercises.

```{r}
# highest posterior density interval of predictions
pred1 <- MCMCvis::MCMCpstr(
  zc_pooled
  , params = c("mu_pred", "log_mu_pred")
  , func = function(x) HDInterval::hdi(x, .95)
)
# median of predictions
pred2 <- MCMCvis::MCMCpstr(
  zc_pooled
  , params = c("mu_pred", "log_mu_pred")
  , func = median
)
# put in data frame
pred.po.df <- dplyr::bind_cols(
  n.input.pred
  , data.frame(pred1$mu_pred)
  , median = pred2$mu_pred
)
lpred.po.df <- dplyr::bind_cols(
  log.n.input.pred = log(n.input.pred)
  , data.frame(pred1$log_mu_pred)
  , median = pred2$log_mu_pred
)
```

Plot the predictions

```{r}
g3 <- g1 +
  geom_line(
    data = pred.po.df
    , mapping = aes(x = n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = pred.po.df
    , mapping = aes(x = n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

g4 <- g2 +
  geom_line(
    data = lpred.po.df
    , mapping = aes(x = log.n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = lpred.po.df
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

gridExtra::grid.arrange(g3, g4, nrow = 1)
```

# Non-Pooled


## Diagramming and writing the no-pool model

Great! - you've got the pooled model fitted and made some predictions from it. However, perhaps the idea of ignoring the site effects is not sitting so well with you. Let's take this a step further by modeling the relationship between $\textrm{N} _2 \textrm{O}$ emission and fertilizer input such that the intercept $\alpha_{j}$ varies by site (we will again ignore the data on soil carbon and fertilizer type). This is the opposite of the pooled model where we completely ignored the effect of site as here we treat the intercept for each site as independent. This is commonly called a no-pool model. The deterministic portion of this model remains a linearized power function, but two subscripts are required: $i$ which indexes the measurement within sites and $j$ which indexes site itself. 


$$
\begin{aligned}
\mu_{ij}  = \gamma_{j} x_{ij}^{\beta}\\
\alpha_{j}  = \log \bigl(\gamma_{j} \bigr)\\
\log \bigl(\mu_{ij} \bigr)  = \alpha_{j}+\beta \bigl(\log(x_{ij}) \bigr)\\
g \bigl(\alpha_{j},\beta,\log(x_{ij}) \bigr)  = \alpha_{j}+\beta \bigl(\log(x_{ij}) \bigr) \\
\end{aligned}
$$


### Question 1 

Draw a Bayesian network for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$). 

```{r, echo=FALSE, out.width="50%", out.height="50%", fig.cap="DAG", fig.align='center'}
knitr::include_graphics("../data/DAG2.jpg")
```

### Question 2 

Write out the joint distribution for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$). Start by using generic `[ ]`. Use $\sigma^{2}$ to represent the uncertainty in your model realizing that you might need moment matching when you choose a specific distribution.

$$
\bigl[ \boldsymbol{\alpha},\beta,\sigma^2 \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n} \prod_{j=1}^{J}  \bigl[ \log(y_{ij})\mid g\bigl(\alpha_{j},\beta,\log(x_{ij})\bigr),\sigma^{2} \bigr] \bigl[\alpha_{j} \bigr] \bigl[ \beta \bigr] \bigl[ \sigma  \bigr]
$$

### Question 3 

Finish by choosing specific distributions for likelihoods and priors. You will use the math in the answer as a template to code your model in the subsequent exercises. 

$$
\begin{aligned}
\bigl[ \boldsymbol{\alpha},\beta,\sigma^2 \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n}  \prod_{j=1}^{J} {\sf normal} \bigr( \log(y_{ij}) \mid g \bigl( \alpha_{j}, \beta, \log(x_{ij})  \bigr), \sigma^{2}\bigr)\\
\times \; {\sf normal} \bigr(\alpha_{j} \mid 0,10000\bigr) \\ 
\times \; {\sf normal} \bigr(\beta \mid 0,10000\bigr) \\
\times \; {\sf uniform}\bigr(\sigma \mid 0, 100 \bigl)
\end{aligned}
$$

### Question 4 

What is the hypothesis represented by this model?

\textcolor{violet}{fill this in!!!!}

## Visualizing the data

Let's visualize the data again, but this time highlighting the role site plays in determining the relationship between $\textrm{N} _2 \textrm{O}$ emission and fertilizer input. First, `head()` the data to see how groups are organized. You will use `group.index` to group the observations by site. 

```{r}
# view the first few rows of data
BayesNSF::N2OEmission %>% 
  head()
# data structure
BayesNSF::N2OEmission %>% 
  dplyr::glimpse()
```

Use the code below to plot logged $\textrm{N} _2 \textrm{O}$ emissions against logged fertilizer input. This is the same ggplot code as before except now we amend it to make plots for individual sites simply by adding the `facet_wrap` function and specifying the grouping variable(here it is `group.index`) as an argument. 

```{r, fig.width=9, fig.height=13}
g2 + facet_wrap(~group.index)
```

### Fitting the no-pool model with JAGS

You will now write a simple, no-pool model using the R template provided below. In addition to fitting this model, we would like you to have JAGS predict the mean logged $\textrm{N} _2 \textrm{O}$ emissions **for each site** as a function of soil fertilizer input. To help you out we have provided the range of $\textrm{N} _2 \textrm{O}$ values to predict over as the third element in the `data` list. **Note that you must use the index trick covered in lecture to align observations in each site with the appropriate intercept**. Here are the preliminaries to set up the model:

```{r}
n.sites <- length(unique(BayesNSF::N2OEmission$group.index))
n.input.pred <- seq(min(BayesNSF::N2OEmission$n.input), max(BayesNSF::N2OEmission$n.input), 10)

data = list(
  log.emission = log(BayesNSF::N2OEmission$emission) %>% as.double()
  , log.n.input.centered = log(BayesNSF::N2OEmission$n.input) - 
      mean(log(BayesNSF::N2OEmission$n.input)) %>% 
        as.double()
  , log.n.input.centered.pred = log(n.input.pred) - 
      mean(log(BayesNSF::N2OEmission$n.input)) %>% 
        as.double()
  , group = BayesNSF::N2OEmission$group.index %>% as.double()
  , n.sites = n.sites
)

inits = list(
  list(alpha = rep(0, n.sites), beta = .5, sigma = 50)
  , list(alpha = rep(1, n.sites), beta = 1.5, sigma = 10)
  , list(alpha = rep(-1, n.sites), beta = .75, sigma = 20)
)
```

### Question 5

Write the code for the model. Compile the model and execute the MCMC to produce a coda object. Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters. Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.


#### JAGS Model

```{r, eval=FALSE}
## JAGS Model
model{
  # priors
  # allow the intercept alpha to vary across sites
    for(j in 1:n.sites){
      alpha[j] ~ dnorm(0,1E-6) 
    }
  # the slope beta is constant across sites
  beta ~ dnorm(0,1E-6)
  sigma ~ dunif(0,100)
  tau <- 1/sigma^2

  # likelihood
  for(i in 1:length(log.emission)) {
    log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
    log.emission[i] ~ dnorm(log_mu[i], tau)
  }

  ## quantities of interest
    # predicted emissions
    ## from the JAGS primer: 
      # If you have two product symbols in the conditional distribution with different indices
        # ...and two subscripts in the quantity of interest i.e. quantity[i, j] 
        # ...then this dual product is specified in JAGS using nested for loops:
    for(i in 1:length(log.n.input.centered.pred)) {
      for(j in 1:n.sites){
        log_mu_site_pred[i, j] <- alpha[j] + beta * log.n.input.centered.pred[i]
      } # end j
    } # end i
}
```

#### Implement JAGS Model

```{r}
##################################################################
# insert JAGS model code into an R script
##################################################################
{ # Extra bracket needed only for R markdown files - see answers
  sink("NO2JAGS_nopooled.R") # This is the file name for the jags code
  cat("
  model{
    # priors
    # allow the intercept alpha to vary across sites
      for(j in 1:n.sites){
        alpha[j] ~ dnorm(0,1E-6) 
      }
    # the slope beta is constant across sites
    beta ~ dnorm(0,1E-6)
    sigma ~ dunif(0,100)
    tau <- 1/sigma^2
  
    # likelihood
    for(i in 1:length(log.emission)) {
      log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
      log.emission[i] ~ dnorm(log_mu[i], tau)
    }
  
    ## quantities of interest
      # predicted emissions
      ## from the JAGS primer: 
        # If you have two product symbols in the conditional distribution with different indices
          # ...and two subscripts in the quantity of interest i.e. quantity[i, j] 
          # ...then this dual product is specified in JAGS using nested for loops:
      for(i in 1:length(log.n.input.centered.pred)) {
        for(j in 1:n.sites){
          log_mu_site_pred[i, j] <- alpha[j] + beta * log.n.input.centered.pred[i]
        } # end j
      } # end i
  }
  ", fill = TRUE)
  sink()
}
################################################################
# implement model
##################################################################
# specify 3 scalars, n.adapt, n.update, and n.iter
# n.adapt = number of iterations that JAGS will use to choose the sampler 
  # and to assure optimum mixing of the MCMC chain
n.adapt = 2000
# n.update = number of iterations that will be discarded to allow the chain to 
#   converge before iterations are stored (aka, burn-in)
n.update = 10000
# n.iter = number of iterations that will be stored in the 
  # final chain as samples from the posterior distribution
n.iter = 10000
######################
# Call to JAGS
######################
jm = rjags::jags.model(
  file = "NO2JAGS_nopooled.R"
  , data = data
  , inits = inits
  , n.chains = length(inits)
  , n.adapt = n.adapt
)
stats::update(jm, n.iter = n.update)
# save the coda object (more precisely, an mcmc.list object) to R as "zc"
zc_nopooled = rjags::coda.samples(
  model = jm
  , variable.names = c("alpha", "beta", "sigma", "tau", "log_mu_site_pred")
  # , variable.names = c("a", "b", "p")
  , n.iter = n.iter
  , n.thin = 1
)
```

#### Model Output

Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters. Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? 

```{r}
#####################
# check output
#####################
# trace plot
MCMCvis::MCMCtrace(zc_nopooled, params = c("beta", "sigma"), pdf = FALSE)

# summary
MCMCvis::MCMCsummary(zc_nopooled, params = c("alpha", "beta", "sigma")) %>% 
  data.frame() %>% 
  dplyr::slice_tail(n = 6)

# Caterpillar plots
MCMCvis::MCMCplot(zc_nopooled, params = c("beta", "sigma"), xlim = c(-0.5,1.5) )

```

```{r, echo=FALSE, eval = FALSE}
# Heidelberger and Welch diagnostic
coda::heidel.diag(zc_nopooled)
```

Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? 

\textcolor{violet}{fill this in!!!!}

Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}
# Caterpillar plots
MCMCvis::MCMCplot(
  zc_nopooled
  , params = c("alpha")
  , horiz = FALSE
  , ylim = c(-6,5)
  # Number specifying size of text for parameter labels on axis.
  , sz_labels = 0.6
  # Number specifying size of points represents posterior medians.
  , sz_med = 0.7
  # Number specifying thickness of 50 percent CI line (thicker line).
  , sz_thick = 2
  # Number specifying thickness of 95 percent CI line (thinner line).
  , sz_thin = 1
)

```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

### Question 6

How is the model able to estimate intercepts for sites where there is only a single x value, or even sites where there is only a single observation at all?

\textcolor{violet}{The model is able to estimate intercepts for sites where there is only a single data record because, in this model, the slope ($\beta$) is calculated using data from all sites. That is, the slope is assumed to be constant across sites. If we also allowed the slope ($\beta$) to vary across sites, then the model would require more than one data point to estimate site-specifice intercept and slope.}

## Visualizing the no-pool model predictions

We modify the `MCMCpstr` code from the previous model to produce a data frame of the median and 95% HDPI credible intervals of $\textrm{N} _2 \textrm{O}$ emission predictions for each site. `MCMCpstr` preserves the shape of the parameter from your JAGS model, which can be very handy in certain situations. Here, `pred1` is a list whose first element is a 3D-array. This array's rows are fertilizer inputs, columns are sites, and z-values are the quantities produced by the `hdi` function, which in this case is the lower and upper credible interval. You can `str` the `pred1[[1]]` object to see this for yourself. For plotting purposes though, we would like a data frame with columns for site, fertilizer input, the posterior's median emission, and the posterior's lower and upper HDPI credible intervals. This can be made easily using the `melt` function to go from wide to long followed by the `spread` function to make separate columns for the lower and upper bounds. Then we rely on `select` and `arrange` to order the data properly and keep the relevant columns. Lastly, we use `cbind` to make the data frame we seek, taking advantage of the fact that `n.input.pred` will repeat each site, which is exactly what we want it to do. 

```{r}
# HDI
pred1 <- MCMCvis::MCMCpstr(
  zc_nopooled
  , params = "log_mu_site_pred"
  , func = function(x) HDInterval::hdi(x, .95)
)
# median
pred2 <- MCMCvis::MCMCpstr(
  zc_nopooled
  , params = "log_mu_site_pred"
  , func = median
)
# create data frame
pred1.df <- reshape2::melt(pred1[[1]], as.is = TRUE, varnames = c("x", "group.index", "metric")) %>% 
  spread(metric, value) %>%
  arrange(group.index, x) %>%
  dplyr::select(group.index, lower, upper)
pred2.df <- reshape2::melt(pred2[[1]], as.is = TRUE, varnames = c("x", "group.index"), value.name = "median") %>%
  arrange(group.index, x) %>% 
  dplyr::select(median)
# cbind
logpred.nopool.df <- cbind(log.n.input.pred = log(n.input.pred), pred1.df, pred2.df)
```

To add the predictions to the plots for each site we use `geom_line` and `geom_ribbon` again, in combination with `facet_wrap`.

```{r, fig.width=9, fig.height=13}
g2 +
  geom_line(
    data = logpred.nopool.df
    , mapping = aes(x = log.n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = logpred.nopool.df
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  ) +
  facet_wrap(~group.index)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[stringr::str_starts(ls(), "pred")])
remove(list = ls()[stringr::str_starts(ls(), "lpred")])
gc()
```

# Random Intercepts

## Diagramming and writing the random intercepts model

So far you have either ignored site completely (the pooled model) or treated all the site intercepts as independent from one another (the no-pool model). Now you are going to treat the site intercepts as partially pooled, meaning you will model them as coming from a common distribution. In other words, you will treat these intercepts in your model as a group level effect (aka, random effect). Hence, this model is often called a random-intercepts model. Like in the no-pool model, the deterministic portion of this model remains a linearized power function, but two subscripts are required: $i$ which indexes the measurement within sites and $j$ which indexes site itself. However, unlike the no-pool model, assume that these intercepts are drawn from a distribution with mean $\mu_{\alpha}$ and variance $\varsigma_{\alpha}^2$.

### Question 1 

Draw a Bayesian network for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$). 

```{r, echo=FALSE, out.width="50%", out.height="50%", fig.cap="DAG", fig.align='center'}
knitr::include_graphics("../data/DAG3.jpg")
```

### Question 2

Write out the posterior and joint distribution for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$). Start by using generic `[ ]`. Use $\sigma^{2}$ and, $\varsigma^{2}$ to represent the uncertainty in your model realizing that you might need moment matching when you choose a specific distribution.

$$
g \bigl(\alpha_{j},\beta,\log(x_{ij}) \bigr) = \alpha_{j} + \beta \bigl(\log(x_ij) \bigr)
$$

Joint:

$$
\bigl[ \alpha_{j},\beta, \mu_{\alpha}, \sigma^2, \varsigma_{\alpha}^2  \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n} \prod_{j=1}^{J}  \bigl[ \log(y_{ij})\mid g\bigl(\alpha_{j}, \beta,\log(x_{ij})\bigr),\sigma^{2} \bigr] \bigl[\alpha_{j} \mid \mu_{\alpha}, \varsigma_{\alpha}^2 \bigr] \bigl[ \beta \bigr] \bigl[ \sigma  \bigr] \bigl[ \varsigma  \bigr]
$$

### Question 3

Finish by choosing specific distributions for likelihoods and priors. You will use the math in the answer as a template to code your model in the subsequent exercises.

$$
\begin{aligned}
\bigl[ \alpha_{j},\beta, \mu_{\alpha}, \sigma^2, \varsigma_{\alpha}^2  \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n}  \prod_{j=1}^{J} {\sf normal} \bigr( \log(y_{ij}) \mid g \bigl( \alpha_{j}, \beta, \log(x_{ij})  \bigr), \sigma^{2}\bigr)\\
\times \; {\sf normal} \bigr(\alpha_{j} \mid \mu_{\alpha}, \varsigma_{\alpha}^2 \bigr) \\ 
\times \; {\sf normal} \bigr(\beta \mid 0,10000\bigr) \\
\times \; {\sf uniform}\bigr(\sigma \mid 0, 100 \bigl) \\
\times \; {\sf uniform}\bigr(\varsigma_{\alpha} \mid 0, 100 \bigl)
\end{aligned}
$$
### Fitting the random intercepts model with JAGS

Now you will implement the random-intercepts model that allows the intercept $\alpha_{j}$ to vary by site, where each intercept is drawn from a common distribution. Use the `data` and initial values for JAGS provided below to allow you to concentrate on writing JAGS code for the model. 

In addition to fitting this model, we would like you to have JAGS predict the mean logged $\textrm{N} _2 \textrm{O}$ emissions **for each site** as a function of soil fertilizer input, just like you did in the no-pool model. We also would like you to predict the mean logged $\textrm{N} _2 \textrm{O}$ emissions and the median unlogged $\textrm{N} _2 \textrm{O}$ emissions as a function of soil fertilizer input, just like you did in the pooled model. However, these predictions should take into account **the uncertainty associated with site**. This is equivalent to asking you to make a prediction for a new site whose intercept $\alpha_{j}$ is drawn from the same distribution as the intercepts are for the actual sites themselves. To help you out we have provided the range of $\textrm{N} _2 \textrm{O}$ values to predict over as the third element in the `data` list.

```{r}
n.input.pred <- seq(min(N2OEmission$n.input), max(N2OEmission$n.input), 10)
n.sites <- length(unique(N2OEmission$group.index))

data = list(
  log.emission = log(N2OEmission$emission),
  log.n.input.centered = log(N2OEmission$n.input) - mean(log(N2OEmission$n.input)),
  log.n.input.centered.pred = log(n.input.pred) - mean(log(N2OEmission$n.input)),
  group = N2OEmission$group.index,
  n.sites = n.sites)

inits = list(
  list(alpha = rep(0, n.sites), beta = .5, sigma = 50, mu_alpha= 0, varsigma = 10),
  list(alpha = rep(1, n.sites), beta = 1.5, sigma = 10, mu_alpha= 2, varsigma = 20),
  list(alpha = rep(-1, n.sites), beta = .75, sigma = 20, mu_alpha= -1, varsigma = 12))
```

### Question 5

Write the code for the model. Compile the model and execute the MCMC to produce a coda object. Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters.  Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

#### JAGS Model

```{r, eval=FALSE}
## JAGS Model
model{
  # priors
  beta ~ dnorm(0,1E-6)
  sigma ~ dunif(0,100)
  tau_y <- 1/sigma^2
  # alpha priors
  mu_alpha ~ dnorm(0,1E-6)
  varsigma ~ dunif(0,100)
  tau_alpha <- 1/varsigma^2
  # allow the intercept alpha to vary across sites
    for(j in 1:n.sites){
      alpha[j] ~ dnorm(mu_alpha, tau_alpha)
    }

  # likelihood
  for(i in 1:length(log.emission)) {
    log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
    log.emission[i] ~ dnorm(log_mu[i], tau_y)
  }

  ## quantities of interest
    # predicted emissions FOR EACH SITE
      ## from the JAGS primer: 
        # If you have two product symbols in the conditional distribution with different indices
          # ...and two subscripts in the quantity of interest i.e. quantity[i, j] 
          # ...then this dual product is specified in JAGS using nested for loops:
      for(i in 1:length(log.n.input.centered.pred)) {
        for(j in 1:n.sites){
          log_mu_site_pred[i, j] <- alpha[j] + beta * log.n.input.centered.pred[i]
        } # end j
      } # end i
    
    # predicted emissions ACROSS SITES
      alpha_pred ~ dnorm(mu_alpha, tau_alpha)
      for(i in 1:length(log.n.input.centered.pred)){
        log_mu_pred[i] <- alpha_pred + beta * log.n.input.centered.pred[i]
        mu_pred[i] <- exp(log_mu_pred[i])
      }
}
```

#### Implement JAGS Model

```{r}
##################################################################
# insert JAGS model code into an R script
##################################################################
{ # Extra bracket needed only for R markdown files - see answers
  sink("NO2JAGS_randomintrcpts.R") # This is the file name for the jags code
  cat("
  model{
    # priors
    beta ~ dnorm(0,1E-6)
    sigma ~ dunif(0,100)
    tau_y <- 1/sigma^2
    # alpha priors
    mu_alpha ~ dnorm(0,1E-6)
    varsigma ~ dunif(0,100)
    tau_alpha <- 1/varsigma^2
    # allow the intercept alpha to vary across sites
      for(j in 1:n.sites){
        alpha[j] ~ dnorm(mu_alpha, tau_alpha)
      }
  
    # likelihood
    for(i in 1:length(log.emission)) {
      log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
      log.emission[i] ~ dnorm(log_mu[i], tau_y)
    }
  
    ## quantities of interest
      # predicted emissions FOR EACH SITE
        ## from the JAGS primer: 
          # If you have two product symbols in the conditional distribution with different indices
            # ...and two subscripts in the quantity of interest i.e. quantity[i, j] 
            # ...then this dual product is specified in JAGS using nested for loops:
        for(i in 1:length(log.n.input.centered.pred)) {
          for(j in 1:n.sites){
            log_mu_site_pred[i, j] <- alpha[j] + beta * log.n.input.centered.pred[i]
          } # end j
        } # end i
      
      # predicted emissions ACROSS SITES
        alpha_pred ~ dnorm(mu_alpha, tau_alpha)
        for(i in 1:length(log.n.input.centered.pred)){
          log_mu_pred[i] <- alpha_pred + beta * log.n.input.centered.pred[i]
          mu_pred[i] <- exp(log_mu_pred[i])
        }
  }
  ", fill = TRUE)
  sink()
}
################################################################
# implement model
##################################################################
# specify 3 scalars, n.adapt, n.update, and n.iter
# n.adapt = number of iterations that JAGS will use to choose the sampler 
  # and to assure optimum mixing of the MCMC chain
n.adapt = 2000
# n.update = number of iterations that will be discarded to allow the chain to 
#   converge before iterations are stored (aka, burn-in)
n.update = 10000
# n.iter = number of iterations that will be stored in the 
  # final chain as samples from the posterior distribution
n.iter = 10000
######################
# Call to JAGS
######################
jm = rjags::jags.model(
  file = "NO2JAGS_randomintrcpts.R"
  , data = data
  , inits = inits
  , n.chains = length(inits)
  , n.adapt = n.adapt
)
stats::update(jm, n.iter = n.update)
# save the coda object (more precisely, an mcmc.list object) to R as "zc"
zc_randomintrcpts = rjags::coda.samples(
  model = jm
  , variable.names = c("alpha", "beta", "sigma", "mu_alpha", "varsigma", "log_mu_site_pred", "log_mu_pred", "mu_pred")
  , n.iter = n.iter
  , n.thin = 1
)
```

#### Model Output

Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters.  Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}
#####################
# check output
#####################
# trace plot
MCMCvis::MCMCtrace(zc_randomintrcpts, params = c("beta", "sigma", "mu_alpha", "varsigma"), pdf = FALSE)

# summary
MCMCvis::MCMCsummary(zc_randomintrcpts, params = c("beta", "sigma", "mu_alpha", "varsigma"))

# Caterpillar plots
MCMCvis::MCMCplot(zc_randomintrcpts, params = c("beta", "sigma", "mu_alpha", "varsigma"), xlim = c(-0.5,1.5) )

```

Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why?

\textcolor{violet}{fill this in!!!!}

Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}
# Caterpillar plots
MCMCvis::MCMCplot(
  zc_randomintrcpts
  , params = c("alpha")
  , horiz = FALSE
  , ylim = c(-6,5)
  # Number specifying size of text for parameter labels on axis.
  , sz_labels = 0.6
  # Number specifying size of points represents posterior medians.
  , sz_med = 0.7
  # Number specifying thickness of 50 percent CI line (thicker line).
  , sz_thick = 2
  # Number specifying thickness of 95 percent CI line (thinner line).
  , sz_thin = 1
)

```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Visualizing the random intercepts model predictions

### Question 6

Modify code from the pooled and no-pool models to visualize the model predictions. For the site-level predictions, add a dotted line showing the posterior median of $\textrm{N} _2 \textrm{O}$ emission from the no-pool model. What do you notice about the uncertainty of predicted log emissions from the random intercept model you fit here compared to the predictions of the pooled model you did in problem 1? Explain the difference.

#### Pooled 

```{r}
# HDI
pred1 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts
  , params = c("log_mu_pred", "mu_pred")
  , func = function(x) HDInterval::hdi(x, .95)
)
# median
pred2 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts
  , params = c("log_mu_pred", "mu_pred")
  , func = median
)
# put in data frame
pred.randomintrcpts.df <- dplyr::bind_cols(
  n.input.pred
  , data.frame(pred1$mu_pred)
  , median = pred2$mu_pred
)
lpred.randomintrcpts.df <- dplyr::bind_cols(
  log.n.input.pred = log(n.input.pred)
  , data.frame(pred1$log_mu_pred)
  , median = pred2$log_mu_pred
)
```

Plot the predictions

```{r}
g5 <- g1 +
  geom_line(
    data = pred.randomintrcpts.df
    , mapping = aes(x = n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = pred.randomintrcpts.df
    , mapping = aes(x = n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

g6 <- g2 +
  geom_line(
    data = lpred.randomintrcpts.df
    , mapping = aes(x = log.n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = lpred.randomintrcpts.df
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

gridExtra::grid.arrange(g5, g6, nrow = 1)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[stringr::str_starts(ls(), "pred")])
remove(list = ls()[stringr::str_starts(ls(), "lpred")])
gc()
```

What do you notice about the uncertainty of predicted log emissions from the random intercept model you fit here compared to the predictions of the pooled model you did in problem 1? Explain the difference.

\textcolor{violet}{fill this in!!!!}

#### Non-Pooled

Plot the predictions

```{r}
# HDI
pred1 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts
  , params = "log_mu_site_pred"
  , func = function(x) HDInterval::hdi(x, .95)
)
# median
pred2 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts
  , params = "log_mu_site_pred"
  , func = median
)
# create data frame
pred1.df <- reshape2::melt(pred1[[1]], as.is = TRUE, varnames = c("x", "group.index", "metric")) %>% 
  spread(metric, value) %>%
  arrange(group.index, x) %>%
  dplyr::select(group.index, lower, upper)
pred2.df <- reshape2::melt(pred2[[1]], as.is = TRUE, varnames = c("x", "group.index"), value.name = "median") %>%
  arrange(group.index, x) %>% 
  dplyr::select(median)
# cbind
logpred.randomintrcpts.df <- cbind(log.n.input.pred = log(n.input.pred), pred1.df, pred2.df)
```

For the site-level predictions, add a dotted line showing the posterior median of $\textrm{N} _2 \textrm{O}$ emission from the no-pool model. 

```{r, fig.width=9, fig.height=13}
g2 +
  geom_ribbon(
    data = logpred.randomintrcpts.df
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  ) +
  # add a dotted line showing...from the no-pool model
  geom_line(
    data = logpred.nopool.df
    , mapping = aes(x = log.n.input.pred, y = median)
    , linetype = "longdash" # cant see dotted so changing 
    , color = "midnightblue"
  ) +
  # random intercepts
  geom_line(
    data = logpred.randomintrcpts.df
    , mapping = aes(x = log.n.input.pred, y = median)
    , linetype = "solid"
    , color = "black"
  ) +
  facet_wrap(~group.index)
```

### Question 7

Why do the intercepts differ for some sites between the no-pool model and the random-intercepts model? Is this behavior consistent? Look closely at sites 51 and 56.

Look closely at sites 51 and 56.

```{r}
temp_grps <- c(51, 56)
ggplot(data = BayesNSF::N2OEmission %>% dplyr::filter(group.index %in% temp_grps)) +
  geom_point(
    mapping = aes(y = log(emission), x = log(n.input))
    , alpha = 3/10
    , shape = 21
    , colour = "black"
    , fill = "brown"
    , size = 3
  ) +
  geom_ribbon(
    data = logpred.randomintrcpts.df %>% dplyr::filter(group.index %in% temp_grps)
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  ) +
  # add a dotted line showing...from the no-pool model
  geom_line(
    data = logpred.nopool.df %>% dplyr::filter(group.index %in% temp_grps)
    , mapping = aes(x = log.n.input.pred, y = median)
    , linetype = "longdash" # cant see dotted so changing 
    , color = "midnightblue"
  ) +
  # random intercepts
  geom_line(
    data = logpred.randomintrcpts.df %>% dplyr::filter(group.index %in% temp_grps)
    , mapping = aes(x = log.n.input.pred, y = median)
    , linetype = "solid"
    , color = "black"
  ) +
  facet_wrap(~group.index
    , labeller = labeller(
        group.index = function(x){paste0("site #", x)}
      )
  ) +
  labs(
    subtitle = "no-pool = dashed, random-intercepts = solid"
  ) +
  theme_minimal() +
  theme(
    plot.subtitle = element_text(face="italic")
  )
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[stringr::str_starts(ls(), "temp_")])
remove(list = ls()[stringr::str_starts(ls(), "pred")])
remove(list = ls()[stringr::str_starts(ls(), "lpred")])
gc()
```

Why do the intercepts differ for some sites between the no-pool model and the random-intercepts model? Is this behavior consistent?

\textcolor{violet}{fill this in!!!! borrowing strength, cnt data obs between sites}

## Diagramming and writing the random intercepts, group-level effect model

In the previous example, we assumed that the variation in the intercept was attributable to spatial variation among sites. We did not try to explain that variation, we simply acknowledged that it exists. Now we are going to "model a parameter" using soil carbon content data at the site-level to explain variation in the intercepts among sites. Modify the previous model to represent the effect of soil carbon on the intercept using the deterministic model below to predict $\alpha_j$. Here, we logit transform the carbon data to "spread them out" mapping 0-1 to all real numbers.

$$
g_2 \bigl(\kappa,\eta, \text{logit}(w_j) \bigr) = \kappa + \eta \bigl(\text{logit}(w_ij) \bigr)
$$ 

### Question 8

Draw a Bayesian network for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$) and soil carbon content ($w_{j}$). 

```{r, echo=FALSE, out.width="50%", out.height="50%", fig.cap="DAG", fig.align='center'}
knitr::include_graphics("../data/DAG4.jpg")
```

### Question 9

Write out the posterior and joint distribution for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ij}$) on fertilizer addition ($x_{ij}$) and soil carbon content ($w_{j}$). Choose appropriate distributions for each random variable. 

$$
\begin{aligned}
g \bigl(\alpha_{j},\beta,\log(x_{ij}) \bigr) = \alpha_{j} + \beta \bigl(\log(x_ij) \bigr)\\
g_2 \bigl(\kappa,\eta, \text{logit}(w_j) \bigr) = \kappa + \eta \bigl(\text{logit}(w_j) \bigr)
\end{aligned}
$$


Joint:


$$
\begin{aligned}
\bigl[ \alpha_{j},\beta, \kappa, \eta, \sigma^2, \varsigma_{\alpha}^2  \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n}  \prod_{j=1}^{J} {\sf normal} \bigr( \log(y_{ij}) \mid g \bigl( \alpha_{j}, \beta, \log(x_{ij})  \bigr), \sigma^{2}\bigr)\\
\times \; {\sf normal} \bigr(\alpha_{j} \mid g_2 \bigl(\kappa,\eta, \text{logit}(w_j) \bigr), \varsigma_{\alpha}^2 \bigr) \\ 
\times \; {\sf normal} \bigr(\beta \mid 0,10000\bigr) \\
\times \; {\sf normal} \bigr(\kappa \mid 0,10000\bigr) \\
\times \; {\sf normal} \bigr(\eta \mid 0,10000\bigr) \\
\times \; {\sf uniform}\bigr(\sigma \mid 0, 100 \bigl) \\
\times \; {\sf uniform}\bigr(\varsigma_{\alpha} \mid 0, 100 \bigl)
\end{aligned}
$$

## Fitting the random intercepts, group-level effect model with JAGS

Modify your random intercepts model to implement the model that include soil carbon content as covariate at the site level. Make predictions for how mean logged $\textrm{N} _2 \textrm{O}$ emission and median $\textrm{N} _2 \textrm{O}$ emission varies with respect to soil fertilizer input **the uncertainty associated with site** as you did in the previous example. Use the `data` and initial values for JAGS provided below to allow you to concentrate on writing JAGS code for the model.

```{r}
n.input.pred <- seq(
  min(BayesNSF::N2OEmission$n.input)
  , max(BayesNSF::N2OEmission$n.input)
  , 10
)
n.sites <- length(unique(BayesNSF::N2OEmission$group.index))

data = list(
  log.emission = log(BayesNSF::N2OEmission$emission)
  , log.n.input.centered = log(BayesNSF::N2OEmission$n.input) - mean(log(BayesNSF::N2OEmission$n.input))
  , log.n.input.centered.pred = log(n.input.pred) - mean(log(BayesNSF::N2OEmission$n.input))
    #divide by 100 to make data a proportion, take logit, and center
  , w = boot::logit(BayesNSF::SiteCarbon$mean/100) - mean(boot::logit(BayesNSF::SiteCarbon$mean/100))
  , group = BayesNSF::N2OEmission$group.index
  , n.sites = n.sites
)

inits = list(
  list(alpha = rep(0, n.sites), beta = .5, sigma = 50, varsigma = 10, eta = .2, kappa = .5)
  , list(alpha = rep(1, n.sites), beta = 1.5, sigma = 10, varsigma = 20, eta = 3, kappa = .7)
  , list(alpha = rep(-1, n.sites), beta = .75, sigma = 20, varsigma = 12, eta = .1, kappa = .3)
)
```

### Question 10

Write the code for the model. Compile the model and execute the MCMC to produce a coda object. Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters. Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

#### JAGS Model

```{r, eval=FALSE}
## JAGS Model
model{
  ## priors
    # y priors
    beta ~ dnorm(0,1E-6)
    sigma ~ dunif(0,100)
    tau_y <- 1/sigma^2
    # alpha priors
    kappa ~ dnorm(0,1E-6)
    eta ~ dnorm(0,1E-6)
    varsigma ~ dunif(0,100)
    tau_alpha <- 1/varsigma^2
  
  ## likelihood
  # intercept (alpha) likelihood
    # represent the effect of soil carbon ...
      # ...on the intercept using the deterministic model below to predict alpha_j
    for(j in 1:n.sites){
      mu_alpha[j] <- kappa + eta * w[j]
      alpha[j] ~ dnorm(mu_alpha[j], tau_alpha)
    }
  # y likelihood
    for(i in 1:length(log.emission)) {
      log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
      log.emission[i] ~ dnorm(log_mu[i], tau_y)
    }

  ## quantities of interest
    # predicted emissions ACROSS SITES
      alpha_pred ~ dnorm(kappa, tau_alpha)
      for(i in 1:length(log.n.input.centered.pred)){
        log_mu_pred[i] <- alpha_pred + beta * log.n.input.centered.pred[i]
        mu_pred[i] <- exp(log_mu_pred[i])
      }
}
```

#### Implement JAGS Model

```{r}
##################################################################
# insert JAGS model code into an R script
##################################################################
{ # Extra bracket needed only for R markdown files - see answers
  sink("NO2JAGS_randomintrcpts_alpha.R") # This is the file name for the jags code
  cat("
  model{
    ## priors
      # y priors
      beta ~ dnorm(0,1E-6)
      sigma ~ dunif(0,100)
      tau_y <- 1/sigma^2
      # alpha priors
      kappa ~ dnorm(0,1E-6)
      eta ~ dnorm(0,1E-6)
      varsigma ~ dunif(0,100)
      tau_alpha <- 1/varsigma^2
    
    ## likelihood
    # intercept (alpha) likelihood
      # represent the effect of soil carbon ...
        # ...on the intercept using the deterministic model below to predict alpha_j
      for(j in 1:n.sites){
        mu_alpha[j] <- kappa + eta * w[j]
        alpha[j] ~ dnorm(mu_alpha[j], tau_alpha)
      }
    # y likelihood
      for(i in 1:length(log.emission)) {
        log_mu[i] <- alpha[group[i]] + beta * log.n.input.centered[i]
        log.emission[i] ~ dnorm(log_mu[i], tau_y)
      }
  
    ## quantities of interest
      # predicted emissions ACROSS SITES
        alpha_pred ~ dnorm(kappa, tau_alpha)
        for(i in 1:length(log.n.input.centered.pred)){
          log_mu_pred[i] <- alpha_pred + beta * log.n.input.centered.pred[i]
          mu_pred[i] <- exp(log_mu_pred[i])
        }
  }
  ", fill = TRUE)
  sink()
}
################################################################
# implement model
##################################################################
# specify 3 scalars, n.adapt, n.update, and n.iter
# n.adapt = number of iterations that JAGS will use to choose the sampler 
  # and to assure optimum mixing of the MCMC chain
n.adapt = 2000
# n.update = number of iterations that will be discarded to allow the chain to 
#   converge before iterations are stored (aka, burn-in)
n.update = 10000
# n.iter = number of iterations that will be stored in the 
  # final chain as samples from the posterior distribution
n.iter = 10000
######################
# Call to JAGS
######################
jm = rjags::jags.model(
  file = "NO2JAGS_randomintrcpts_alpha.R"
  , data = data
  , inits = inits
  , n.chains = length(inits)
  , n.adapt = n.adapt
)
stats::update(jm, n.iter = n.update)
# save the coda object (more precisely, an mcmc.list object) to R as "zc"
zc_randomintrcpts_alpha = rjags::coda.samples(
  model = jm
  , variable.names = c("alpha", "beta", "sigma", "kappa", "eta", "varsigma", "log_mu_pred", "mu_pred")
  , n.iter = n.iter
  , n.thin = 1
)
```

#### Model Output

Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters. Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}
#####################
# check output
#####################
# trace plot
MCMCvis::MCMCtrace(zc_randomintrcpts_alpha, params = c("beta", "sigma", "kappa", "eta", "varsigma"), pdf = FALSE)

# summary
MCMCvis::MCMCsummary(zc_randomintrcpts_alpha, params = c("beta", "sigma", "kappa", "eta", "varsigma"))

# Caterpillar plots
MCMCvis::MCMCplot(zc_randomintrcpts_alpha, params = c("beta", "sigma", "kappa", "eta", "varsigma"), xlim = c(-0.5,1.5) )

```

Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why?

\textcolor{violet}{fill this in!!!!}

Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}
# Caterpillar plots
MCMCvis::MCMCplot(
  zc_randomintrcpts_alpha
  , params = c("alpha")
  , horiz = FALSE
  , ylim = c(-6,5)
  # Number specifying size of text for parameter labels on axis.
  , sz_labels = 0.6
  # Number specifying size of points represents posterior medians.
  , sz_med = 0.7
  # Number specifying thickness of 50 percent CI line (thicker line).
  , sz_thick = 2
  # Number specifying thickness of 95 percent CI line (thinner line).
  , sz_thin = 1
)

```

## Visualizing random intercepts, group-level effect model predictions

### Question 11

Use the code from the pooled to visualize the model predictions again. Compared to the random effects model, how does modeling site soil carbon affect the uncertainty in predicting $\textrm{N} _2 \textrm{O}$ emissions for new sites?

```{r}
# HDI
pred1 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts_alpha
  , params = c("log_mu_pred", "mu_pred")
  , func = function(x) HDInterval::hdi(x, .95)
)
# median
pred2 <- MCMCvis::MCMCpstr(
  zc_randomintrcpts_alpha
  , params = c("log_mu_pred", "mu_pred")
  , func = median
)
# put in data frame
pred.randomintrcpts_alpha.df <- dplyr::bind_cols(
  n.input.pred
  , data.frame(pred1$mu_pred)
  , median = pred2$mu_pred
)
lpred.randomintrcpts_alpha.df <- dplyr::bind_cols(
  log.n.input.pred = log(n.input.pred)
  , data.frame(pred1$log_mu_pred)
  , median = pred2$log_mu_pred
)
```

Plot the predictions

```{r, fig.cap="Pooled - random intercepts, group-level effect model", fig.height=5, fig.width=7}
g7 <- g1 +
  geom_line(
    data = pred.randomintrcpts_alpha.df
    , mapping = aes(x = n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = pred.randomintrcpts_alpha.df
    , mapping = aes(x = n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

g8 <- g2 +
  geom_line(
    data = lpred.randomintrcpts_alpha.df
    , mapping = aes(x = log.n.input.pred, y = median)
  ) +
  geom_ribbon(
    data = lpred.randomintrcpts_alpha.df
    , mapping = aes(x = log.n.input.pred, ymin = lower, ymax = upper)
    , alpha = 0.2
    , fill = "yellow"
  )

gridExtra::grid.arrange(g7, g8, nrow = 1)
```

```{r, fig.cap="Pooled - random intercepts, No group-level effect model", fig.height=5, fig.width=7}
gridExtra::grid.arrange(g5, g6, nrow = 1)
```

Compared to the random effects model, how does modeling site soil carbon affect the uncertainty in predicting $\textrm{N} _2 \textrm{O}$ emissions for new sites?

\textcolor{violet}{fill this in!!!!}

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[stringr::str_starts(ls(), "pred")])
remove(list = ls()[stringr::str_starts(ls(), "lpred")])
gc()
```

# Random Coefficients

## Diagramming and writing the random carbon fertilizer model

Now we are interested in the effect of soil carbon and fertilizer type on $\textrm{N} _2 \textrm{O}$ emissions. Model the effect of carbon as above, but include a group level effect of fertilizer type on the slope of the emission vs fertilizer addition model. This is to say that the slopes of the regressions are drawn from a distribution of fertilizer types. Index plot with $i$, site with $j$, and fertilizer type with $k$. Thus, there will be $K$ slopes, one for each fertilizer type, drawn from a distribution with mean $\mu_{\beta}$ and variance $\varsigma_{\beta}^{2}$. Modify the carbon model you built in the previous step to incorporate effect of fertilizer type.  

Be careful here because the group level effects are formed for two **separate** groups, site and fertilizer type. You might be tempted (or perhaps terrified) to think that you need to model the covariance in this problem, which is not the case. This is required only if you are modeling slope and intercept as group level effects for the **same** grouping variable, for example, site. You will see how this is done in the last problem. Think about it. Covariance between the slope and intercept is only important if they are being estimated from data within the same group. There is only a singe fertilizer type with each group, so it cannot covary with the intercept.

### Question 1

Draw a Bayesian network for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ijk}$) on fertilizer addition ($x_{ijk}$) and soil carbon content $(w_{j})$.

```{r, echo=FALSE, out.width="50%", out.height="50%", fig.cap="DAG", fig.align='center'}
knitr::include_graphics("../data/DAG5.jpg")
```

### Question 2

Write out the posterior and joint distributions for a linear regression model of $\textrm{N} _2 \textrm{O}$ emission ($y_{ijk}$) on fertilizer addition ($x_{ijk}$) and soil carbon content ($w_{j}$). Choose appropriate distributions for each random variable.


$$
\begin{aligned}
g \bigl(\alpha_{j},\beta_{k},\log(x_{ijk}) \bigr) = \alpha_{j} + \beta_{k} \bigl(\log(x_ijk) \bigr)\\
g_2 \bigl(\kappa,\eta, \text{logit}(w_j) \bigr) = \kappa + \eta \bigl(\text{logit}(w_j) \bigr)
\end{aligned}
$$


Joint:


$$
\begin{aligned}
\bigl[ \alpha_{j},\beta_{k}, \kappa, \eta, \mu_{\beta}, \sigma^2, \varsigma_{\alpha}^2, \varsigma_{\beta}^2  \mid \boldsymbol{y} \bigr] \propto \prod_{i=1}^{n}  \prod_{j=1}^{J} \prod_{k=1}^{K} {\sf normal} \bigr( \log(y_{ijk}) \mid g \bigl( \alpha_{j}, \beta_{k}, \log(x_{ijk})  \bigr), \sigma^{2}\bigr)\\
\times \; {\sf normal} \bigr(\alpha_{j} \mid g_2 \bigl(\kappa,\eta, \text{logit}(w_j) \bigr), \varsigma_{\alpha}^2 \bigr) \\ 
\times \; {\sf normal} \bigr(\beta_{k} \mid \mu_{\beta}, \varsigma_{\beta}^2 \bigr) \\
\times \; {\sf normal} \bigr(\kappa \mid 0,10000\bigr) \\
\times \; {\sf normal} \bigr(\eta \mid 0,10000\bigr) \\
\times \; {\sf normal} \bigr(\mu_{\beta} \mid 0,10000\bigr) \\
\times \; {\sf uniform}\bigr(\sigma \mid 0, 100 \bigl) \\
\times \; {\sf uniform}\bigr(\varsigma_{\alpha} \mid 0, 100 \bigl) \\
\times \; {\sf uniform}\bigr(\varsigma_{\beta} \mid 0, 100 \bigl)
\end{aligned}
$$



### Fitting the random carbon fertilizer model with JAGS

Modify your random intercepts model to implement the model that include soil carbon content and fertilizer type as covariates at the site level. Use the `data` and initial values for JAGS provided below to allow you to concentrate on writing JAGS code for the model.

```{r}
n.sites <- length(unique(N2OEmission$group.index))
n.ferts <- length(unique(N2OEmission$fert.index))

data = list(
  log.emission = log(N2OEmission$emission),
  log.n.input.centered = log(N2OEmission$n.input) - mean(log(N2OEmission$n.input)),
  #take logit and center.  You will need the boot library
  w = boot::logit(SiteCarbon$mean) - mean(boot::logit(SiteCarbon$mean)),
  fertilizer = N2OEmission$fert.index, 
  group = N2OEmission$group.index,
  n.sites = n.sites,
  n.ferts = n.ferts)

inits = list(
  list(alpha = rep(0, n.sites), beta = rep(0, n.ferts), sigma = 50, varsigma_alpha = 10, varsigma_beta = .2,
    mu_beta = .1, eta = .2, kappa = .5),
  list(alpha = rep(1, n.sites), beta = rep(2, n.ferts), sigma = 10, varsigma_alpha = 20, varsigma_beta = .1, 
    mu_beta = 3, eta = 3, kappa = .7),
  list(alpha = rep(-1, n.sites), beta = rep(1, n.ferts), sigma = 20, varsigma_alpha = 12, varsigma_beta = .3,
    mu_beta = -2, eta = .1, kappa = .3))
```

### Question 3

Write the code for the model. Compile the model and execute the MCMC to produce a coda object. Produce trace plots of the chains for model parameters, excluding $\boldsymbol{\alpha}$ and a summary table of these same parameters. Assess convergence and look at the effective sample sizes for each of these parameters. Do you think any of the chains need to be run for longer and if so why? Make a horizontal caterpillar plot for the the $\boldsymbol{\alpha}$.

```{r}

```


### Question 4

How do you assess whether fertilizer type a good predictor of $\textrm{N} _2 \textrm{O}$ emission?  How would we compare the slope for fertilizer type 1 to type 5?

```{r}

```

